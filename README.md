# ğŸ“„ LLaMA Summarizer - Streamlit App

This project is a **local/offline PDF & Text Summarizer** powered by **Meta LLaMA 3 8B Instruct GGUF** model, wrapped in a **Streamlit UI**. It allows you to upload `.pdf` or `.txt` files and generates a concise summary, also saving the output to a **PDF in the `Output/` folder**.

---

## ğŸ“ Directory Structure

```
llama_summarizer_streamlit/
â”œâ”€â”€ app.py                # Streamlit UI entrypoint
â”œâ”€â”€ utils.py              # File parsing, LLM interaction, and PDF saving utilities
â”œâ”€â”€ requirements.txt      # Required Python dependencies
â”œâ”€â”€ models/               # Contains the GGUF LLaMA model file
â”‚   â””â”€â”€ Meta-Llama-3-8B-Instruct-Q4_K_M.gguf
â”œâ”€â”€ Output/               # Summarized PDFs are saved here
â””â”€â”€ README.md             # You're reading it now
```

---

## ğŸš€ Features

- ğŸ“¤ Upload PDF or TXT
- ğŸ“š View extracted content (first 3K characters)
- ğŸ§  Summarize using LLaMA 3 (running locally)
- ğŸ“„ Save summary as `<input_filename>_summary.pdf` in the `Output` folder

---

## ğŸ§‘â€ğŸ’» Setup Instructions

### 1. âœ… Clone the Repository

```bash
git clone https://github.com/prashant12jul/llama_summarizer_streamlit.git
cd llama_summarizer_streamlit
```

### 2. ğŸ“¦ Create Virtual Environment

```bash
python -m venv venv
.env\Scriptsctivate      # Windows
# OR
source venv/bin/activate     # macOS/Linux
```

### 3. ğŸ”§ Install Requirements

```bash
pip install -r requirements.txt
```

---

## ğŸ¤– Download the LLaMA Model (Offline)

Download from Hugging Face and place the `.gguf` model file into `models/`:

```bash
pip install huggingface_hub
huggingface-cli download bartowski/Meta-Llama-3-8B-Instruct-GGUF Meta-Llama-3-8B-Instruct-Q4_K_M.gguf   --local-dir ./models --local-dir-use-symlinks False
```

> Ensure the final path looks like:  
> `models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf`

---

## â–¶ï¸ Run the Streamlit App

```bash
streamlit run app.py
```

- Go to: `http://localhost:8501`
- Upload a file â†’ Click "Generate Summary" â†’ View and Save the result

---

## ğŸ“ Example Output

After summarization, you'll get a PDF saved as:

```
Output/
â”œâ”€â”€ your_uploaded_file_summary.pdf
```

---

## ğŸ“¦ Requirements

Minimal `requirements.txt`:

```
streamlit
fpdf
llama-cpp-python>=0.2.24
PyMuPDF
huggingface_hub
```

---

## ğŸ™‹â€â™‚ï¸ Author

**Prashant Kumar**  
ğŸ”— GitHub: [@prashant12jul](https://github.com/prashant12jul)

---

## ğŸ“„ License

This project is for educational and local inference purposes only. All model rights belong to their respective owners (Meta AI).
